{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f345ca-5436-4b64-bb14-f42f59999742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils.data_for_train_phi import get_dataset_for_train_phi\n",
    "from prompts.teleqna_prompts import get_full_promt_teleqna\n",
    "from prompts.covid_prompts import get_full_promt_covid\n",
    "from prompts.boolq_prompts import get_full_promt_boolq\n",
    "from prompts.clapnq_prompts import get_full_promt_clapnq\n",
    "from prompts.covid_prompts import get_full_promt_covid\n",
    "from utils.datasets_splits import load_dataset_splits\n",
    "from prompts.teleqna_prompts import get_full_promt_teleqna, format_input_context_teleqna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e4da95-d85a-40ce-9df1-800e09bb0cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing datasets...\n",
      "Train: 1292\n",
      "Val: 323\n",
      "Test: 404\n",
      "Datasets loaded and prepared.\n"
     ]
    }
   ],
   "source": [
    "train, val, test = load_dataset_splits('covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b383b23-79e6-48d6-af55-89a2118c5447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instruct: Answer the question based on your knowledge.\\nQuestion:\\nAs of 26 January 2020, what countries had sporadic cases?\\n\\nOutput:\\nwere reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_full_promt_covid(train[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2779e623-354a-4263-bfa9-2f97f7e66268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing datasets...\n",
      "Train: 7541\n",
      "Val: 1886\n",
      "Test: 3270\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Instruct: Answer the question based on your knowledge. Answer only \"yes\" or \"no\" .\\nQuestion:\\ncan you sail from lake ontario to lake erie\\n\\nOutput:\\nTrue'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val, test = load_dataset_splits('boolq')\n",
    "get_full_promt_boolq(train[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c69b830-55d1-43b4-a7c5-a11c92b8f9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing datasets...\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m load_dataset_splits(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclapnq\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_full_promt_clapnq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local1/ronaldinho/projects/FinalSBBD/notebooks/../src/prompts/clapnq_prompts.py:72\u001b[0m, in \u001b[0;36mget_full_promt_clapnq\u001b[0;34m(row, include_docs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(include_docs):\n\u001b[1;32m     71\u001b[0m     context \u001b[38;5;241m=\u001b[39m get_context(row)\n\u001b[0;32m---> 72\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[43mformat_input_context_clapnq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m answer \u001b[38;5;241m=\u001b[39m get_answer(row)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/local1/ronaldinho/projects/FinalSBBD/notebooks/../src/prompts/clapnq_prompts.py:27\u001b[0m, in \u001b[0;36mformat_input_context_clapnq\u001b[0;34m(row, context)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_input_context_clapnq\u001b[39m(row, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     question_text \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context:\n\u001b[1;32m     29\u001b[0m         input_text \u001b[38;5;241m=\u001b[39m template_RAG\u001b[38;5;241m.\u001b[39msubstitute(\n\u001b[1;32m     30\u001b[0m             question\u001b[38;5;241m=\u001b[39mquestion_text,\n\u001b[1;32m     31\u001b[0m             context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m     32\u001b[0m         )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "train, val, test = load_dataset_splits('clapnq')\n",
    "get_full_promt_clapnq(train[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c52e5f2-cf04-4252-a134-9ba76fd4af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '-1253448975620540114',\n",
       " 'input': '\\u200ba budget prepared by the president and submitted to congress is called the',\n",
       " 'passages': [{'title': 'United States budget process',\n",
       "   'text': \"The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year . The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions . In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests . The documents are also posted on the OMB website . \",\n",
       "   'sentences': ['The United States budget process begins when the President of the United States submits a budget request to Congress .',\n",
       "    \"The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President .\",\n",
       "    'The budget request includes funding requests for all federal executive departments and independent agencies .',\n",
       "    'Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications .',\n",
       "    \"The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year .\",\n",
       "    'The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions .',\n",
       "    'In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests .',\n",
       "    'The documents are also posted on the OMB website .']}],\n",
       " 'output': [{'answer': \"It is called the President's budget request.\",\n",
       "   'selected_sentences': ['The United States budget process begins when the President of the United States submits a budget request to Congress .'],\n",
       "   'meta': {'annotator': [46373812, 46545946],\n",
       "    'has_minimal_answer': False,\n",
       "    'non_consecutive': True,\n",
       "    'round': 2,\n",
       "    'skip': False}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b0ea97-a5d0-462a-8a89-908ab691c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdinho15971\u001b[0m (\u001b[33mdinho15971-unicamp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/local1/ronaldinho/projects/FinalSBBD/notebooks/wandb/run-20250429_231521-jyetqr9v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mphi-2-rag-k1_covidV2-5e_10bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters/runs/jyetqr9v\u001b[0m\n",
      "Usando dispositivo: cuda\n",
      "üíæ  Vector store cargado desde ../vector_stores/covid/ft_vector_store_covid\n",
      "Generating dataset\n",
      "Using k = 3 passages\n",
      "Loading and preparing datasets...\n",
      "Train: 1292\n",
      "Val: 323\n",
      "Test: 404\n",
      "Datasets loaded and prepared.\n",
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:01<00:00, 82.94it/s]\n",
      "Example\n",
      "Instruct:  Using the information in the context, answer the question as concisely and faithfully as possible.If the context does not provide enough information to answer confidently, answer based on the most likely interpretation from the given text.\n",
      "\n",
      "Context:\n",
      "\n",
      "Document 0:. Nonetheless, the virus spread from Wuhan to other cities in China and outside the country. By February 4, 2020, a total of 23 locations outside mainland China reported cases, 22 of which reported imported cases; Spain reported a case caused by secondary transmission (3).\n",
      "Document 1:. As of 26 January 2020, the still ongoing outbreak had resulted in 2066 (618 of them are in Wuhan) confirmed cases and 56 (45 of them were in Wuhan) deaths in mainland China [4] , and sporadic cases exported from Wuhan were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and the United States, please see the World Health Organization (WHO) news release via https://www.who.int/csr/don/en/ from 14 to 21 January 2020\n",
      "Document 2:066 (618 of them are in Wuhan) confirmed cases and 56 (45 of them were in Wuhan) deaths in mainland China [4] , and sporadic cases exported from Wuhan were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and the United States, please see the World Health Organization (W\n",
      "Document 3:As of 24 January 2020, the cumulative incidence in China is 830 cases, of which 549 cases were diagnosed in Hubei, 26 in Beijing, 20 in Shanghai, and 53 in Guangdong. Additionally, twenty-six deaths have been linked to the outbreak [6, 8] , and thirteen cases were exported to Japan, Singapore, South Korea, Taiwan, Thailand, Vietnam and the United States as of 22 January 2020. Considering that enhanced surveillance has been underway in these importing countries, case ascertainment has been perhaps better in exported case data.\n",
      "\n",
      "Question:\n",
      "As of 26 January 2020, what countries had sporadic cases?\n",
      "\n",
      "Output:\n",
      "['were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and']\n",
      "Loading model\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.71it/s]\n",
      "Training\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "üü¢ No checkpoints found. Starting training from scratch.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/ft_phi.py \\\n",
    "  --new_model_name \"phi-2-rag-k1_covidV2-5e_10bs\" \\\n",
    "  --num_epochs 5 \\\n",
    "  --batch_size 10 \\\n",
    "  --dataset_name \"covid\" \\\n",
    "  --include_docs \\\n",
    "  --top_k 3 \\\n",
    "  --save_path \"../models/covid/adapters/\" \\\n",
    "  --vector_store_path \"../vector_stores/covid/ft_vector_store_covid\" \\\n",
    "  --emb_model \"../models/covid/embedding/bge-small-covid_10e_128bs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b14ea-0d8b-4fae-b9c7-fad91ecdae82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (env_1)",
   "language": "python",
   "name": "env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
