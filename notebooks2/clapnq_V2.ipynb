{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139c38c8-8865-439a-af75-9f3520fed08e",
   "metadata": {},
   "source": [
    "# ClapNQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b68689-7554-49d5-b7e5-13132ffcc2f6",
   "metadata": {},
   "source": [
    "## Create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac6ad01-3256-4d7e-a79c-5c95f50e4865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding\n",
      "Using device: cuda\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178890/178890 [00:06<00:00, 28154.16it/s]\n",
      "  0%|                                     | 330/178890 [00:00<03:33, 836.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178890/178890 [04:15<00:00, 699.53it/s]\n",
      "Total number of passages: 263742\n",
      "Removing duplicate passages\n",
      "Total number of passages created: 261999\n",
      "Creating vector store\n",
      "Load model embedding : BAAI/bge-small-en-v1.5\n",
      "Using device: cuda\n",
      "Generando embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:45<00:00,  1.14it/s]\n",
      "‚úÖ √çndice FAISS creado exitosamente.\n",
      "üíæ Vector store saved in ../vector_stores/clapnq/base_vs_clapnq_150_20\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/create_vector_store.py \\\n",
    "  --dataset \"clapnq\" \\\n",
    "  --emb_model \"BAAI/bge-small-en-v1.5\" \\\n",
    "  --cs 150 \\\n",
    "  --co 20 \\\n",
    "  --bs_emb 1024 \\\n",
    "  --output_dir \"../vector_stores/clapnq/base_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddfa907-15e1-4574-8d6c-ee13b0d634e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding : BAAI/bge-small-en-v1.5\n",
      "Using device: cuda\n",
      "üíæ Vector store loaded from../vector_stores/clapnq/base_vs_clapnq_150_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['Yellowstone (U.S. TV series), Principal photography for the series began in August 2017 at the Chief Joseph Ranch in Darby , Montana , which stands in as the home of John Dutton . Filming also took place that month near Park City , Utah . The production used all three soundstages at the Utah Film Studio in Park City , which is a total of 45,000 square feet . The building also houses offices , editing , a huge wardrobe department and construction shops . By November 2017 , the series had filmed in more than twenty locations in Utah , including the Salt Flats and Spanish Fork . Additionally , filming also took place at various locations in Montana . Production was reportedly set to last until December 2017 .',\n",
       "   'Yellowstone (U.S. TV series), In 2013 , Taylor Sheridan began work on the series , having recently grown tired of acting and begun writing screenplays . Having lived in the rural parts of states such as Texas and Wyoming , Sheridan purposely set the series in Montana and went about writing the first scripts in Livingston .'],\n",
       "  array([0.88373935, 0.7949742 ], dtype=float32))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vector_stores.faiss import VectorStoreFaiss\n",
    "vector_store = VectorStoreFaiss.load_local(\"../vector_stores/clapnq/base_vs_clapnq_150_20\")\n",
    "results = vector_store.buscar_por_batches(['where are they filming the tv series yellowstone?'],2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf71a69-bd74-48b7-9b57-04ad88cf4d0d",
   "metadata": {},
   "source": [
    "## Train Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49126775-f4bf-4501-badf-985316ee3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'q_id': '-1253448975620540114',\n",
       " 'question': '\\u200ba budget prepared by the president and submitted to congress is called the',\n",
       " 'relevant_docs': \"United States budget process, The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year . The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions . In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests . The documents are also posted on the OMB website . \"}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from utils.data_for_train_emb import load_and_prepare_datasets\n",
    "train_dataset, val_dataset, test_dataset = load_and_prepare_datasets('clapnq')\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6964965f-2990-4842-813d-eea54a0c2118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdinho15971\u001b[0m (\u001b[33mdinho15971-unicamp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "Starting main process...\n",
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Datasets loaded and prepared.\n",
      "Creating evaluator...\n",
      "Evaluator created.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/local1/ronaldinho/projects/test_sbbd/notebooks2/wandb/run-20250502_194028-uee8rwae\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbge-small-clapnq_10e_128bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings/runs/uee8rwae\u001b[0m\n",
      "Loading model: BAAI/bge-small-en-v1.5\n",
      "Model and loss function initialized.\n",
      "Configuring training arguments...\n",
      "Training arguments configured.\n",
      "Starting training process...\n",
      "{'loss': 0.7902, 'grad_norm': 3.0498111248016357, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.625}\n",
      "{'eval_loss': 0.2954702079296112, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8825100133511349, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9546061415220294, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9746328437917223, 'eval_telecom-ir-eval_cosine_precision@1': 0.8825100133511349, 'eval_telecom-ir-eval_cosine_recall@1': 0.8825100133511349, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9338679602836919, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9165554072096128, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9190921228304407, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9202783605654098, 'eval_telecom-ir-eval_cosine_map@100': 0.9211199567478914, 'eval_runtime': 2.1315, 'eval_samples_per_second': 351.397, 'eval_steps_per_second': 2.815, 'epoch': 0.625}\n",
      "{'loss': 0.2904, 'grad_norm': 1.839694857597351, 'learning_rate': 4.993392291751431e-05, 'epoch': 1.25}\n",
      "{'eval_loss': 0.185517355799675, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8945260347129506, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9586114819759679, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9692923898531375, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9773030707610146, 'eval_telecom-ir-eval_cosine_precision@1': 0.8945260347129506, 'eval_telecom-ir-eval_cosine_recall@1': 0.8945260347129506, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.94114965948078, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9256786826880286, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9280818869603917, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9290864009155065, 'eval_telecom-ir-eval_cosine_map@100': 0.929756762174569, 'eval_runtime': 2.1434, 'eval_samples_per_second': 349.441, 'eval_steps_per_second': 2.799, 'epoch': 1.25}\n",
      "{'loss': 0.1791, 'grad_norm': 1.6471189260482788, 'learning_rate': 4.894973780788722e-05, 'epoch': 1.875}\n",
      "{'eval_loss': 0.16940268874168396, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.9038718291054739, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9639519359145527, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9692923898531375, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9799732977303071, 'eval_telecom-ir-eval_cosine_precision@1': 0.9038718291054739, 'eval_telecom-ir-eval_cosine_recall@1': 0.9038718291054739, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9464048037483197, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9323542501112594, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9336226079216733, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9352014325979611, 'eval_telecom-ir-eval_cosine_map@100': 0.9356685064997488, 'eval_runtime': 2.1482, 'eval_samples_per_second': 348.658, 'eval_steps_per_second': 2.793, 'epoch': 1.875}\n",
      "{'loss': 0.1083, 'grad_norm': 1.2243444919586182, 'learning_rate': 4.68301438693049e-05, 'epoch': 2.5}\n",
      "{'eval_loss': 0.1665761023759842, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.9065420560747663, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9706275033377837, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9799732977303071, 'eval_telecom-ir-eval_cosine_precision@1': 0.9065420560747663, 'eval_telecom-ir-eval_cosine_recall@1': 0.9065420560747663, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9475237751166912, 'eval_telecom-ir-eval_cosine_mrr@3': 0.934134401424121, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9353360035603026, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9366923093224826, 'eval_telecom-ir-eval_cosine_map@100': 0.9372454711311063, 'eval_runtime': 2.1467, 'eval_samples_per_second': 348.905, 'eval_steps_per_second': 2.795, 'epoch': 2.5}\n",
      "{'loss': 0.0824, 'grad_norm': 0.924457848072052, 'learning_rate': 4.36756267810249e-05, 'epoch': 3.125}\n",
      "{'eval_loss': 0.1648811399936676, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9746328437917223, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9826435246995995, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9460943136335449, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9307966177125057, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9329327992879395, 'eval_telecom-ir-eval_cosine_mrr@10': 0.933911352703075, 'eval_telecom-ir-eval_cosine_map@100': 0.9342169325915936, 'eval_runtime': 2.1334, 'eval_samples_per_second': 351.089, 'eval_steps_per_second': 2.812, 'epoch': 3.125}\n",
      "{'loss': 0.0565, 'grad_norm': 0.9262462258338928, 'learning_rate': 3.963573584424852e-05, 'epoch': 3.75}\n",
      "{'eval_loss': 0.16645215451717377, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9626168224299065, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9706275033377837, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9799732977303071, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9444569047531756, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9294615042278594, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9313306631063641, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9326228622290038, 'eval_telecom-ir-eval_cosine_map@100': 0.9331624742472864, 'eval_runtime': 2.1256, 'eval_samples_per_second': 352.375, 'eval_steps_per_second': 2.823, 'epoch': 3.75}\n",
      "{'loss': 0.0438, 'grad_norm': 0.29163283109664917, 'learning_rate': 3.490199415097892e-05, 'epoch': 4.375}\n",
      "{'eval_loss': 0.16547641158103943, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.9012016021361816, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9626168224299065, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9692923898531375, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.9012016021361816, 'eval_telecom-ir-eval_cosine_recall@1': 0.9012016021361816, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9452993822555961, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9301290609701824, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9317311971517579, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9333810159577851, 'eval_telecom-ir-eval_cosine_map@100': 0.9337910388995995, 'eval_runtime': 2.1448, 'eval_samples_per_second': 349.221, 'eval_steps_per_second': 2.798, 'epoch': 4.375}\n",
      "{'loss': 0.0412, 'grad_norm': 0.0787879005074501, 'learning_rate': 2.9698818860002797e-05, 'epoch': 5.0}\n",
      "{'eval_loss': 0.16355851292610168, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9626168224299065, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9732977303070761, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9452569203791973, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9296840231419671, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9321539830885625, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9332305507872929, 'eval_telecom-ir-eval_cosine_map@100': 0.9336512923534731, 'eval_runtime': 2.1208, 'eval_samples_per_second': 353.164, 'eval_steps_per_second': 2.829, 'epoch': 5.0}\n",
      "{'loss': 0.0385, 'grad_norm': 0.7842267155647278, 'learning_rate': 2.4272882031422215e-05, 'epoch': 5.625}\n",
      "{'eval_loss': 0.1637028306722641, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9639519359145527, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9452925848016993, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9301290609701824, 'eval_telecom-ir-eval_cosine_mrr@5': 0.931998219848687, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9332824718672513, 'eval_telecom-ir-eval_cosine_map@100': 0.9336517078286297, 'eval_runtime': 2.1534, 'eval_samples_per_second': 347.828, 'eval_steps_per_second': 2.786, 'epoch': 5.625}\n",
      "{'loss': 0.0329, 'grad_norm': 0.42257997393608093, 'learning_rate': 1.8881416401141904e-05, 'epoch': 6.25}\n",
      "{'eval_loss': 0.16434331238269806, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9453426046420649, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9305740987983978, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9320427236315088, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9333418102443467, 'eval_telecom-ir-eval_cosine_map@100': 0.9337017822924109, 'eval_runtime': 2.135, 'eval_samples_per_second': 350.814, 'eval_steps_per_second': 2.81, 'epoch': 6.25}\n",
      "{'loss': 0.0285, 'grad_norm': 0.2208167165517807, 'learning_rate': 1.3780020494988446e-05, 'epoch': 6.875}\n",
      "{'eval_loss': 0.16446812450885773, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9453731438326852, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9305740987983978, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9320427236315088, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9333735986606478, 'eval_telecom-ir-eval_cosine_map@100': 0.9337279376233748, 'eval_runtime': 2.1689, 'eval_samples_per_second': 345.344, 'eval_steps_per_second': 2.766, 'epoch': 6.875}\n",
      "{'loss': 0.0293, 'grad_norm': 0.3959081172943115, 'learning_rate': 9.210541217437565e-06, 'epoch': 7.5}\n",
      "{'eval_loss': 0.16356563568115234, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8985313751668892, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8985313751668892, 'eval_telecom-ir-eval_cosine_recall@1': 0.8985313751668892, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9452154409972858, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9303515798842901, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9318202047174009, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9331341259245128, 'eval_telecom-ir-eval_cosine_map@100': 0.9335227407853993, 'eval_runtime': 2.1279, 'eval_samples_per_second': 351.997, 'eval_steps_per_second': 2.82, 'epoch': 7.5}\n",
      "{'loss': 0.0277, 'grad_norm': 0.6707800030708313, 'learning_rate': 5.389608377010608e-06, 'epoch': 8.125}\n",
      "{'eval_loss': 0.16338996589183807, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9455333855805396, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9307966177125055, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9322652425456164, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9335791637527283, 'eval_telecom-ir-eval_cosine_map@100': 0.9339648159822855, 'eval_runtime': 2.1251, 'eval_samples_per_second': 352.461, 'eval_steps_per_second': 2.823, 'epoch': 8.125}\n",
      "{'loss': 0.0281, 'grad_norm': 0.39390918612480164, 'learning_rate': 2.4983647033969714e-06, 'epoch': 8.75}\n",
      "{'eval_loss': 0.1634686291217804, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9455333855805396, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9307966177125055, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9322652425456164, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9335791637527283, 'eval_telecom-ir-eval_cosine_map@100': 0.93396630493165, 'eval_runtime': 2.1356, 'eval_samples_per_second': 350.721, 'eval_steps_per_second': 2.81, 'epoch': 8.75}\n",
      "{'loss': 0.0225, 'grad_norm': 0.6987253427505493, 'learning_rate': 6.738782355044049e-07, 'epoch': 9.375}\n",
      "{'eval_loss': 0.16351675987243652, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9455333855805396, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9307966177125055, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9322652425456164, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9335791637527283, 'eval_telecom-ir-eval_cosine_map@100': 0.9339527977526844, 'eval_runtime': 2.153, 'eval_samples_per_second': 347.879, 'eval_steps_per_second': 2.787, 'epoch': 9.375}\n",
      "{'loss': 0.0267, 'grad_norm': 0.2703448534011841, 'learning_rate': 2.6442018223132857e-09, 'epoch': 10.0}\n",
      "{'eval_loss': 0.163533553481102, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.965287049399199, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9719626168224299, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9813084112149533, 'eval_telecom-ir-eval_cosine_precision@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_recall@1': 0.8998664886515354, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.9455333855805396, 'eval_telecom-ir-eval_cosine_mrr@3': 0.9307966177125055, 'eval_telecom-ir-eval_cosine_mrr@5': 0.9322652425456164, 'eval_telecom-ir-eval_cosine_mrr@10': 0.9335791637527283, 'eval_telecom-ir-eval_cosine_map@100': 0.933953442735044, 'eval_runtime': 2.123, 'eval_samples_per_second': 352.801, 'eval_steps_per_second': 2.826, 'epoch': 10.0}\n",
      "{'train_runtime': 168.3888, 'train_samples_per_second': 177.922, 'train_steps_per_second': 1.425, 'train_loss': 0.11413248802224794, 'epoch': 10.0}\n",
      "Training completed.\n",
      "Saving the trained model...\n",
      "Model saved successfully.\n",
      "Process completed successfully.\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mbge-small-clapnq_10e_128bs\u001b[0m at: \u001b[34mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings/runs/uee8rwae\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250502_194028-uee8rwae/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/train_embedding.py \\\n",
    "  --name_dataset \"clapnq\" \\\n",
    "  --model_name \"BAAI/bge-small-en-v1.5\" \\\n",
    "  --new_model_name \"bge-small-clapnq\" \\\n",
    "  --epochs 10 \\\n",
    "  --batch_size 128 \\\n",
    "  --output_dir \"../models/clapnq/embedding/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07508b1-0d1d-4bb5-bfd8-c0c6a60949a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluate Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0145c8bc-7e97-4517-8eba-955e7b097f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos...\n",
      "Models loaded\n",
      "Loading datasets...\n",
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Datasets loaded and prepared.\n",
      "Loaded dataset\n",
      "Creating evaluator...\n",
      "Evaluator created.\n",
      "Evaluating models\n",
      "Save results...\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/evaluate_embedding.py \\\n",
    "  --name_dataset \"clapnq\" \\\n",
    "  --output_dir \"../results/clapnq/\" \\\n",
    "  --models_dir \"../models/clapnq/embedding/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831fded-b089-456a-848b-4da1fd8880ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating new Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd969c8-cc50-4cb5-9885-876960f44b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding\n",
      "Using device: cuda\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178890/178890 [00:06<00:00, 29252.16it/s]\n",
      "  0%|                                     | 332/178890 [00:00<03:34, 831.05it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178890/178890 [04:13<00:00, 705.09it/s]\n",
      "Total number of passages: 263742\n",
      "Removing duplicate passages\n",
      "Total number of passages created: 261999\n",
      "Creating vector store\n",
      "Load model embedding : ../models/clapnq/embedding/bge-small-clapnq_10e_128bs\n",
      "Using device: cuda\n",
      "Generando embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:47<00:00,  1.12it/s]\n",
      "‚úÖ √çndice FAISS creado exitosamente.\n",
      "üíæ Vector store saved in ../vector_stores/clapnq/ft_vs_clapnq_150_20\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/create_vector_store.py \\\n",
    "  --dataset \"clapnq\" \\\n",
    "  --emb_model \"../models/clapnq/embedding/bge-small-clapnq_10e_128bs\" \\\n",
    "  --cs 150 \\\n",
    "  --co 20 \\\n",
    "  --bs_emb 1024 \\\n",
    "  --output_dir \"../vector_stores/clapnq/ft_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090613c1-a963-4d21-ba7a-169e101560f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding : ../models/clapnq/embedding/bge-small-clapnq_10e_128bs\n",
      "Using device: cuda\n",
      "üíæ Vector store loaded from../vector_stores/clapnq/ft_vs_clapnq_150_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['Yellowstone (U.S. TV series), Principal photography for the series began in August 2017 at the Chief Joseph Ranch in Darby , Montana , which stands in as the home of John Dutton . Filming also took place that month near Park City , Utah . The production used all three soundstages at the Utah Film Studio in Park City , which is a total of 45,000 square feet . The building also houses offices , editing , a huge wardrobe department and construction shops . By November 2017 , the series had filmed in more than twenty locations in Utah , including the Salt Flats and Spanish Fork . Additionally , filming also took place at various locations in Montana . Production was reportedly set to last until December 2017 .',\n",
       "   'Yellowstone (U.S. TV series), In 2013 , Taylor Sheridan began work on the series , having recently grown tired of acting and begun writing screenplays . Having lived in the rural parts of states such as Texas and Wyoming , Sheridan purposely set the series in Montana and went about writing the first scripts in Livingston .'],\n",
       "  array([0.939727  , 0.90734386], dtype=float32))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vector_stores.faiss import VectorStoreFaiss\n",
    "vector_store = VectorStoreFaiss.load_local(\"../vector_stores/clapnq/ft_vs_clapnq_150_20\")\n",
    "results = vector_store.buscar_por_batches(['where are they filming the tv series yellowstone?'],2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec2237-5382-498a-923a-29e8d124ffc5",
   "metadata": {},
   "source": [
    "## Train Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2137212-9218-44c4-89c9-d759c65e7584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding : ../models/clapnq/embedding/bge-small-clapnq_10e_128bs\n",
      "Using device: cuda\n",
      "üíæ Vector store loaded from../vector_stores/clapnq/ft_vs_clapnq_150_20\n",
      "Creating dataset for clapnq\n",
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 22.80it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4ed1742a1c48b3a1f5e7989c4b7c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2996 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:04<00:00, 22.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de87f68bfc4048728aee046a1c034006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6b273653874db78018a5253d1cb6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from utils.data_for_train_phi import get_dataset_for_train_phi\n",
    "from vector_stores.faiss import VectorStoreFaiss\n",
    "vector_store = VectorStoreFaiss.load_local(\"../vector_stores/clapnq/ft_vs_clapnq_150_20\")\n",
    "train_ds, test_ds = get_dataset_for_train_phi('clapnq', True, vector_store,4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef47bd5-77b2-4971-81db-3e3e9d4a5828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Using the information in the context, answer the question as concisely and faithfully as possible. If the context does not contain enough information,  respond with unanswerable.\n",
      "Context:\n",
      "\n",
      "Document 0:United States budget process, The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year\n",
      "Document 1:. The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions . In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests . The documents are also posted on the OMB website .\n",
      "Document 2:United States budget process, The Budget and Accounting Act of 1921 requires the President to submit the budget to Congress for each fiscal year , which is the 12 - month period beginning on October 1 and ending on September 30 of the next calendar year . The current federal budget law ( 31 U.S.C. ¬ß 1105 ( a ) ) requires that the President submit the budget between the first Monday in January and the first Monday in February . In recent times , the President 's budget submission has been issued in the first week of February . The budget submission has been delayed , however , in some new presidents ' first year when the previous president belonged to a different party\n",
      "Document 3:United States budget process, Prior to 1974 , Congress had no formal process for establishing a federal budget . When President Richard Nixon began to refuse to spend funds that Congress had allocated , they adopted a more formal means by which to challenge him . The Congressional Budget Act of 1974 created the Congressional Budget Office ( CBO ) , which gained more control of the budget , limiting the power of the President 's Office of Management and Budget ( OMB ) . The Act passed easily while the administration was embroiled in the Watergate scandal and was unwilling to provoke Congress .\n",
      "Document 4:United States budget process, The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year\n",
      "Document 5:. The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions . In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests . The documents are also posted on the OMB website .\n",
      "\n",
      "Question:\n",
      "‚Äãa budget prepared by the president and submitted to congress is called the\n",
      "\n",
      "Output:\n",
      "It is called the President's budget request.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be29613-3cd1-465c-a627-0e879243190c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdinho15971\u001b[0m (\u001b[33mdinho15971-unicamp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/local1/ronaldinho/projects/test_sbbd/notebooks2/wandb/run-20250502_204507-3t92ckzg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mphi_2_rag_k1_clapnq-5e_10bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters/runs/3t92ckzg\u001b[0m\n",
      "Usando dispositivo: cuda\n",
      "Load model embedding : ../models/clapnq/embedding/bge-small-clapnq_10e_128bs\n",
      "Using device: cuda\n",
      "üíæ Vector store loaded from../vector_stores/clapnq/ft_vs_clapnq_150_20\n",
      "Using k = 1 passages\n",
      "Creating dataset for clapnq\n",
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:17<00:00, 21.35it/s]\n",
      "Map:  41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 1222/2996 [04:53<06:14,  4.73 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 1365/2996 [05:25<06:08,  4.43 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2601/2996 [10:08<01:28,  4.45 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2996/2996 [11:41<00:00,  4.27 examples/s]\n",
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:04<00:00, 20.66it/s]\n",
      "Map:  44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 329/749 [01:14<01:35,  4.38 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 676/749 [02:33<00:15,  4.70 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 743/749 [02:52<00:01,  3.00 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 749/749 [02:54<00:00,  4.30 examples/s]\n",
      "Input Example:\n",
      "Instruct: Using the information in the context, answer the question as concisely and faithfully as possible. If the context does not contain enough information,  respond with unanswerable.\n",
      "Context:\n",
      "\n",
      "Document 0:United States budget process, The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year\n",
      "Document 1:United States budget process, The United States budget process begins when the President of the United States submits a budget request to Congress . The President 's budget is formulated over a period of months with the assistance of the Office of Management and Budget ( OMB ) , the largest office within the Executive Office of the President . The budget request includes funding requests for all federal executive departments and independent agencies . Budget documents include supporting documents and historical budget data and contains detailed information on spending and revenue proposals , along with policy proposals and initiatives with significant budgetary implications . The President 's budget request constitutes an extensive proposal of the administration 's intended revenue and spending plans for the following fiscal year\n",
      "Document 2:. The budget proposal includes volumes of supporting information intended to persuade Congress of the necessity and value of the budget provisions . In addition , each federal executive department and independent agency provides additional detail and supporting documentation on its own funding requests . The documents are also posted on the OMB website .\n",
      "\n",
      "Question:\n",
      "‚Äãa budget prepared by the president and submitted to congress is called the\n",
      "\n",
      "Output:\n",
      "It is called the President's budget request.\n",
      "<|endoftext|>\n",
      "Loading model\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s]\n",
      "Training\n",
      "Converting train dataset to ChatML: 100%|‚ñà| 2996/2996 [00:00<00:00, 10764.48 exa\n",
      "Adding EOS to train dataset: 100%|‚ñà| 2996/2996 [00:00<00:00, 18131.04 examples/s\n",
      "Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà| 2996/2996 [00:02<00:00, 1112.51 examples/s]\n",
      "Truncating train dataset: 100%|‚ñà‚ñà‚ñà| 2996/2996 [00:00<00:00, 12289.47 examples/s]\n",
      "Converting eval dataset to ChatML: 100%|‚ñà| 749/749 [00:00<00:00, 15745.46 exampl\n",
      "Adding EOS to eval dataset: 100%|‚ñà‚ñà‚ñà| 749/749 [00:00<00:00, 13999.58 examples/s]\n",
      "Tokenizing eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 749/749 [00:00<00:00, 1099.72 examples/s]\n",
      "Truncating eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 749/749 [00:00<00:00, 11377.50 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "üü¢ No checkpoints found. Starting training from scratch.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "{'loss': 2.0768, 'grad_norm': 0.24006730318069458, 'learning_rate': 0.00019946119873266613, 'epoch': 0.3333333333333333}\n",
      "{'eval_loss': 1.7618647813796997, 'eval_runtime': 52.6365, 'eval_samples_per_second': 14.23, 'eval_steps_per_second': 1.425, 'eval_num_tokens': 446833.0, 'eval_mean_token_accuracy': 0.6289385016759237, 'epoch': 0.3333333333333333}\n",
      "{'loss': 1.7532, 'grad_norm': 0.18746094405651093, 'learning_rate': 0.00019491669984901379, 'epoch': 0.6666666666666666}\n",
      "{'eval_loss': 1.6673601865768433, 'eval_runtime': 52.5401, 'eval_samples_per_second': 14.256, 'eval_steps_per_second': 1.427, 'eval_num_tokens': 857552.0, 'eval_mean_token_accuracy': 0.6467572363217672, 'epoch': 0.6666666666666666}\n",
      "{'loss': 1.7071, 'grad_norm': 0.1780630201101303, 'learning_rate': 0.00018594617189587512, 'epoch': 1.0}\n",
      "{'eval_loss': 1.6414015293121338, 'eval_runtime': 52.6899, 'eval_samples_per_second': 14.215, 'eval_steps_per_second': 1.423, 'eval_num_tokens': 1250441.0, 'eval_mean_token_accuracy': 0.6500579611460368, 'epoch': 1.0}\n",
      "{'loss': 1.6812, 'grad_norm': 0.16362908482551575, 'learning_rate': 0.000172967916579403, 'epoch': 1.3333333333333333}\n",
      "{'eval_loss': 1.6287837028503418, 'eval_runtime': 52.7367, 'eval_samples_per_second': 14.203, 'eval_steps_per_second': 1.422, 'eval_num_tokens': 1695835.0, 'eval_mean_token_accuracy': 0.6516593488057455, 'epoch': 1.3333333333333333}\n",
      "{'loss': 1.652, 'grad_norm': 0.17216038703918457, 'learning_rate': 0.0001565871186078025, 'epoch': 1.6666666666666665}\n",
      "{'eval_loss': 1.619627594947815, 'eval_runtime': 52.4697, 'eval_samples_per_second': 14.275, 'eval_steps_per_second': 1.429, 'eval_num_tokens': 2107245.0, 'eval_mean_token_accuracy': 0.653816614151001, 'epoch': 1.6666666666666665}\n",
      "{'loss': 1.6459, 'grad_norm': 0.18659338355064392, 'learning_rate': 0.00013756762552443553, 'epoch': 2.0}\n",
      "{'eval_loss': 1.6141637563705444, 'eval_runtime': 52.5219, 'eval_samples_per_second': 14.261, 'eval_steps_per_second': 1.428, 'eval_num_tokens': 2500882.0, 'eval_mean_token_accuracy': 0.6545754996935527, 'epoch': 2.0}\n",
      "{'loss': 1.6121, 'grad_norm': 0.1780804693698883, 'learning_rate': 0.00011679632898701649, 'epoch': 2.3333333333333335}\n",
      "{'eval_loss': 1.6117171049118042, 'eval_runtime': 52.5633, 'eval_samples_per_second': 14.249, 'eval_steps_per_second': 1.427, 'eval_num_tokens': 2950070.0, 'eval_mean_token_accuracy': 0.6552274306615193, 'epoch': 2.3333333333333335}\n",
      "{'loss': 1.6257, 'grad_norm': 0.20642711222171783, 'learning_rate': 9.524180841762577e-05, 'epoch': 2.6666666666666665}\n",
      "{'eval_loss': 1.6079994440078735, 'eval_runtime': 52.4424, 'eval_samples_per_second': 14.282, 'eval_steps_per_second': 1.43, 'eval_num_tokens': 3359617.0, 'eval_mean_token_accuracy': 0.6564358592033386, 'epoch': 2.6666666666666665}\n",
      "/local1/ronaldinho/enviroments/env_sbbd/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/phi-2/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff55e7eebc0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 3b0976d0-00e5-42c0-aede-1290819a8705)') - silently ignoring the lookup for the file config.json in microsoft/phi-2.\n",
      "  warnings.warn(\n",
      "/local1/ronaldinho/enviroments/env_sbbd/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in microsoft/phi-2 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 1.6153, 'grad_norm': 0.23567970097064972, 'learning_rate': 7.390916549774536e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 1.6070258617401123, 'eval_runtime': 52.509, 'eval_samples_per_second': 14.264, 'eval_steps_per_second': 1.428, 'eval_num_tokens': 3751323.0, 'eval_mean_token_accuracy': 0.6567736021677653, 'epoch': 3.0}\n",
      "{'loss': 1.586, 'grad_norm': 0.19684220850467682, 'learning_rate': 5.379315560596038e-05, 'epoch': 3.3333333333333335}\n",
      "{'eval_loss': 1.6067320108413696, 'eval_runtime': 52.3188, 'eval_samples_per_second': 14.316, 'eval_steps_per_second': 1.434, 'eval_num_tokens': 4195813.0, 'eval_mean_token_accuracy': 0.656977580388387, 'epoch': 3.3333333333333335}\n",
      "{'loss': 1.5933, 'grad_norm': 0.218760147690773, 'learning_rate': 3.583180171067101e-05, 'epoch': 3.6666666666666665}\n",
      "{'eval_loss': 1.6058940887451172, 'eval_runtime': 52.4271, 'eval_samples_per_second': 14.287, 'eval_steps_per_second': 1.431, 'eval_num_tokens': 4605811.0, 'eval_mean_token_accuracy': 0.6566025924682617, 'epoch': 3.6666666666666665}\n",
      "{'loss': 1.595, 'grad_norm': 0.25408387184143066, 'learning_rate': 2.0862653732958915e-05, 'epoch': 4.0}\n",
      "{'eval_loss': 1.606521725654602, 'eval_runtime': 52.5743, 'eval_samples_per_second': 14.247, 'eval_steps_per_second': 1.427, 'eval_num_tokens': 5001764.0, 'eval_mean_token_accuracy': 0.6567697787284851, 'epoch': 4.0}\n",
      "{'loss': 1.5983, 'grad_norm': 0.2085448056459427, 'learning_rate': 9.583733034714981e-06, 'epoch': 4.333333333333333}\n",
      "{'eval_loss': 1.6048393249511719, 'eval_runtime': 52.2994, 'eval_samples_per_second': 14.321, 'eval_steps_per_second': 1.434, 'eval_num_tokens': 5441311.0, 'eval_mean_token_accuracy': 0.656992936929067, 'epoch': 4.333333333333333}\n",
      "{'loss': 1.5787, 'grad_norm': 0.22507135570049286, 'learning_rate': 2.520983216615047e-06, 'epoch': 4.666666666666667}\n",
      "{'eval_loss': 1.605774164199829, 'eval_runtime': 52.4427, 'eval_samples_per_second': 14.282, 'eval_steps_per_second': 1.43, 'eval_num_tokens': 5853579.0, 'eval_mean_token_accuracy': 0.6568627452850342, 'epoch': 4.666666666666667}\n",
      "{'loss': 1.5594, 'grad_norm': 0.2583807408809662, 'learning_rate': 3.745016960665648e-09, 'epoch': 5.0}\n",
      "{'eval_loss': 1.6054266691207886, 'eval_runtime': 52.5165, 'eval_samples_per_second': 14.262, 'eval_steps_per_second': 1.428, 'eval_num_tokens': 6252205.0, 'eval_mean_token_accuracy': 0.6569364436467489, 'epoch': 5.0}\n",
      "{'train_runtime': 4247.4928, 'train_samples_per_second': 3.527, 'train_steps_per_second': 0.088, 'train_loss': 1.658668182373047, 'num_tokens': 6252205.0, 'mean_token_accuracy': 0.6457768335342408, 'epoch': 5.0}\n",
      "trainable parameters: 26214400\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mphi_2_rag_k1_clapnq-5e_10bs\u001b[0m at: \u001b[34mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters/runs/3t92ckzg\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250502_204507-3t92ckzg/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/ft_phi.py \\\n",
    "  --new_model_name \"phi_2_rag_k1_clapnq-5e_10bs\" \\\n",
    "  --num_epochs 5 \\\n",
    "  --batch_size 10 \\\n",
    "  --dataset_name \"clapnq\" \\\n",
    "  --include_docs \\\n",
    "  --top_k 1 \\\n",
    "  --save_path \"../models/clapnq/adapters/\" \\\n",
    "  --vector_store_path \"../vector_stores/clapnq/ft_vs_clapnq_150_20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036721cc-e913-4c85-8e88-13a0d07f3bf6",
   "metadata": {},
   "source": [
    "## inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399ea629-5df9-47e1-a50b-bbf69761f22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading base model from LoRA adapter: ../models/clapnq/adapters/best_phi_2_rag_k1_clapnq-5e_10bs\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 18.76it/s]\n",
      "Load model embedding : ../models/clapnq/embedding/bge-small-clapnq_10e_128bs\n",
      "Using device: cuda\n",
      "üíæ Vector store loaded from../vector_stores/clapnq/ft_vs_clapnq_150_20\n",
      "Device set to use cuda:0\n",
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Dataset({\n",
      "    features: ['id', 'question', 'passages', 'output'],\n",
      "    num_rows: 600\n",
      "})\n",
      "üîç Buscando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.34it/s]\n",
      "Generating prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:00<00:00, 7979.17it/s]\n",
      "Example prompt\n",
      "Instruct: Using the information in the context, answer the question as concisely and faithfully as possible. If the context does not contain enough information,  respond with unanswerable.\n",
      "Context:\n",
      "\n",
      "Document 1:Forecasting, Forecasting has applications in a wide range of fields where estimates of future conditions are useful . Not everything can be forecasted reliably , if the factors that relate to what is being forecast are known and well understood and there is a significant amount of data that can be used very reliable forecasts can often be obtained . If this is not the case or if the actual outcome is effected by the forecasts , the reliability of the forecasts can be significantly lower .\n",
      "Document 2:Forecasting, As proposed by Edward Lorenz in 1963 , long range weather forecasts , those made at a range of two weeks or more , are impossible to definitively predict the state of the atmosphere , owing to the chaotic nature of the fluid dynamics equations involved . Extremely small errors in the initial input , such as temperatures and winds , within numerical models double every five days .\n",
      "Document 3:Forecasting, A variation on the na√Øve method is to allow the forecasts to increase or decrease over time , where the amount of change over time ( called the drift ) is set to be the average change seen in the historical data . So the forecast for time T + h ( \\ displaystyle T + h ) is given by\n",
      "\n",
      "Question:\n",
      "which method of forecasting uses averages to predict future weather\n",
      "\n",
      "Output:\n",
      "Processing inference\n",
      "inference completed\n",
      "answer save in ../results/clapnq/full_ft_clapnq_k3_V4.csv\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/inference_rag.py \\\n",
    "  --lora_adapter_path \"../models/clapnq/adapters/best_phi_2_rag_k1_clapnq-5e_10bs\" \\\n",
    "  --max_new_tokens 150 \\\n",
    "  --vector_store_path \"../vector_stores/clapnq/ft_vs_clapnq_150_20\" \\\n",
    "  --dataset_name \"clapnq\" \\\n",
    "  --output_csv_path \"../results/clapnq/full_ft_clapnq_k3_V4.csv\" \\\n",
    "  --bs_emb 50 \\\n",
    "  --bs_gen 8 \\\n",
    "  --top_k 3 \\\n",
    "  --use_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8dfa3-57da-4cf4-9995-01e07a38e03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python ../scripts/inference_rag.py \\\n",
    "  --lora_adapter_path \"../models/clapnq/adapters/phi_2_rag_k1_clapnq-5e_10bs/checkpoint-375\" \\\n",
    "  --max_new_tokens 150 \\\n",
    "  --vector_store_path \"../vector_stores/clapnq/ft_vs_clapnq_150_20\" \\\n",
    "  --dataset_name \"clapnq\" \\\n",
    "  --output_csv_path \"../results/clapnq/full_ft_clapnq_V2.csv\" \\\n",
    "  --bs_emb 50 \\\n",
    "  --bs_gen 8 \\\n",
    "  --top_k 10 \\\n",
    "  --use_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf9da9-9c07-4580-97b8-6449c218305c",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227229d5-5a17-44c2-85d9-28c1c676fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Results saved in: ../results/clapnq/v1_full_ft_clapnq.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('clapnq', '../results/clapnq/v1_full_ft_clapnq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc66225-7d04-4905-b28d-e32b1c5ca5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Results saved in: ../results/clapnq/full_ft_clapnq_V2.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('clapnq', '../results/clapnq/full_ft_clapnq_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1aa57ee-aeed-49c1-a6cd-8184b530a61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Results saved in: ../results/clapnq/full_ft_clapnq_k5_V3.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('clapnq', '../results/clapnq/full_ft_clapnq_k5_V3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028ef71c-29df-40dd-bf93-e8fc03887f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "Results saved in: ../results/clapnq/full_ft_clapnq_k3_V4.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('clapnq', '../results/clapnq/full_ft_clapnq_k3_V4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dca86-3d40-4b11-a5e3-2c3022ed814d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (env_sbbd)",
   "language": "python",
   "name": "env_sbbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
